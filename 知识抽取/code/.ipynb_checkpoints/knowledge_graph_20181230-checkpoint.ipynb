{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: 利用信息抽取技术搭建知识库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目的目的是结合命名实体识别、依存语法分析、实体消歧、实体统一对网站开放语料抓取的数据建立小型知识图谱。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1：开发句法结构分析工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 开发工具\n",
    "使用CYK算法，根据所提供的：非终结符集合、终结符集合、规则集，对以下句子计算句法结构。\n",
    "\n",
    "“the boy saw the dog with a telescope\"\n",
    "\n",
    "\n",
    "\n",
    "非终结符集合：N={S, NP, VP, PP, DT, Vi, Vt, NN, IN}\n",
    "\n",
    "终结符集合：{sleeps, saw, boy, girl, dog, telescope, the, with, in}\n",
    "\n",
    "规则集: R={\n",
    "- (1) S-->NP VP 1.0\n",
    "- (2) VP-->VI 0.3\n",
    "- (3) VP-->Vt NP 0.4\n",
    "- (4) VP-->VP PP 0.3\n",
    "- (5) NP-->DT NN 0.8\n",
    "- (6) NP-->NP PP 0.2\n",
    "- (7) PP-->IN NP 1.0\n",
    "- (8) Vi-->sleeps 1.0\n",
    "- (9) Vt-->saw 1.0\n",
    "- (10) NN-->boy 0.1\n",
    "- (11) NN-->girl 0.1\n",
    "- (12) NN-->telescope 0.3\n",
    "- (13) NN-->dog 0.5\n",
    "- (14) DT-->the 0.5\n",
    "- (15) DT-->a 0.5\n",
    "- (16) IN-->with 0.6\n",
    "- (17) IN-->in 0.4\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分数（15）\n",
    "class my_CYK(object):\n",
    "    def __init__(self, non_ternimal, terminal, rules_prob, start_prob):\n",
    "        self.non_terminal = non_ternimal\n",
    "        self.terminal = terminal\n",
    "        self.rules_prob = rules_prob\n",
    "        self.start_symbol = start_prob\n",
    "\n",
    "\n",
    "    def parse_sentence(self, sentence):\n",
    "        sents = sentence.split()\n",
    "        best_path = [[{} for _ in range(len(sents))] for _ in range(len(sents))]\n",
    "\n",
    "        # initialization\n",
    "        for i in range(len(sents)):\n",
    "            for x in self.non_terminal:\n",
    "                best_path[i][i][x] = {}\n",
    "                if (sents[i],) in self.rules_prob[x].keys():\n",
    "                    best_path[i][i][x]['prob'] = self.rules_prob[x][(sents[i],)]\n",
    "                    best_path[i][i][x]['path'] = {'split':None, 'rule': sents[i]}\n",
    "                else:\n",
    "                    best_path[i][i][x]['prob'] = 0\n",
    "                    best_path[i][i][x]['path'] = {'split':None, 'rule': None}\n",
    "\n",
    "        # CKY recursive\n",
    "        for l in range(1, len(sents)):\n",
    "            for i in range(len(sents)-l):\n",
    "                j = i + l\n",
    "                for x in self.non_terminal:\n",
    "                    tmp_best_x = {'prob':0, 'path':None}\n",
    "                    for key, value in self.rules_prob[x].items():\n",
    "                        if key[0] not in self.non_terminal: \n",
    "                            break\n",
    "                        for s in range(i, j):\n",
    "                            tmp_prob = value * best_path[i][s][key[0]]['prob'] * best_path[s+1][j][key[1]]['prob']\n",
    "                            if tmp_prob > tmp_best_x['prob']:\n",
    "                                tmp_best_x['prob'] = tmp_prob\n",
    "                                tmp_best_x['path'] = {'split': s, 'rule': key}\n",
    "                    best_path[i][j][x] = tmp_best_x\n",
    "        self.best_path = best_path\n",
    "\n",
    "        # parse result\n",
    "        self._parse_result(0, len(sents)-1, self.start_symbol)\n",
    "        print(\"prob = \", self.best_path[0][len(sents)-1][self.start_symbol]['prob'])\n",
    "\n",
    "\n",
    "    def _parse_result(self, left_idx, right_idx, root, ind=0):\n",
    "        node = self.best_path[left_idx][right_idx][root]\n",
    "        if node['path']['split'] is not None:\n",
    "            print('\\t'*ind, (root, self.rules_prob[root].get(node['path']['rule'])))\n",
    "            self._parse_result(left_idx, node['path']['split'], node['path']['rule'][0], ind+1)\n",
    "            self._parse_result(node['path']['split']+1, right_idx, node['path']['rule'][1], ind+1)\n",
    "        else:\n",
    "            print('\\t'*ind, (root, self.rules_prob[root].get((node['path']['rule'],))) )\n",
    "            print('--->', node['path']['rule'])\n",
    "\n",
    "\n",
    "\n",
    "def main(sentence):\n",
    "    non_terminal = {'S', 'NP', 'VP', 'PP', 'DT', 'Vi', 'Vt', 'NN', 'IN'}\n",
    "    start_symbol = 'S'\n",
    "    terminal = {'sleeps', 'saw', 'boy', 'girl', 'dog', 'telescope', 'the', 'with', 'in'}\n",
    "    rules_prob = {'S': {('NP', 'VP'): 1.0},\n",
    "                  'VP': {('Vt', 'NP'): 0.8, ('VP', 'PP'): 0.2},\n",
    "                  'NP': {('DT', 'NN'): 0.8, ('NP', 'PP'): 0.2},\n",
    "                  'PP': {('IN', 'NP'): 1.0},\n",
    "                  'Vi': {('sleeps',): 1.0},\n",
    "                  'Vt': {('saw',): 1.0},\n",
    "                  'NN': {('boy',): 0.1, ('girl',): 0.1,('telescope',): 0.3,('dog',): 0.5},\n",
    "                  'DT': {('the',): 1.0},\n",
    "                  'IN': {('with',): 0.6, ('in',): 0.4},\n",
    "                }\n",
    "    cyk = my_CYK(non_terminal, terminal, rules_prob, start_symbol)\n",
    "    cyk.parse_sentence(sentence)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ('S', 1.0)\n",
      "\t ('NP', 0.8)\n",
      "\t\t ('DT', 1.0)\n",
      "---> the\n",
      "\t\t ('NN', 0.1)\n",
      "---> boy\n",
      "\t ('VP', 0.2)\n",
      "\t\t ('VP', 0.8)\n",
      "\t\t\t ('Vt', 1.0)\n",
      "---> saw\n",
      "\t\t\t ('NP', 0.8)\n",
      "\t\t\t\t ('DT', 1.0)\n",
      "---> the\n",
      "\t\t\t\t ('NN', 0.5)\n",
      "---> dog\n",
      "\t\t ('PP', 1.0)\n",
      "\t\t\t ('IN', 0.6)\n",
      "---> with\n",
      "\t\t\t ('NP', 0.8)\n",
      "\t\t\t\t ('DT', 1.0)\n",
      "---> the\n",
      "\t\t\t\t ('NN', 0.3)\n",
      "---> telescope\n",
      "prob =  0.0007372800000000003\n"
     ]
    }
   ],
   "source": [
    "# TODO: 对该测试用例进行测试\n",
    "# \"the boy saw the dog with the telescope\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sentence = \"the boy saw the dog with the telescope\"\n",
    "    main(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 计算算法复杂度\n",
    "计算上一节开发的算法所对应的时间复杂度和空间复杂度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分数（3）\n",
    "# 上面所写的算法的时间复杂度和空间复杂度分别是多少？\n",
    "# TODO\n",
    "时间复杂度=O(), 空间复杂度=O()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2 基于Bootstrapping，抽取企业股权交易关系，并建立知识库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 练习实体消歧\n",
    "将句中识别的实体与知识库中实体进行匹配，解决实体歧义问题。\n",
    "可利用上下文本相似度进行识别。\n",
    "\n",
    "在data/entity_disambiguation目录中，entity_list.csv是50个实体，valid_data.csv是需要消歧的语句（待添加）。\n",
    "\n",
    "答案提交在submit目录中，命名为entity_disambiguation_submit.csv。格式为：第一列是需要消歧的语句序号，第二列为多个“实体起始位坐标-实体结束位坐标：实体序号”以“|”分隔的字符串。\n",
    "\n",
    "*成绩以实体识别准确率以及召回率综合的F值评分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "# 将识别出的实体与知识库中实体进行匹配，解决识别出一个实体对应知识库中多个实体的问题。\n",
    "\n",
    "# 将entity_list.csv中已知实体的名称导入分词词典\n",
    "\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "entity_data = pd.read_csv('../data/entity_disambiguation/entity_list.csv', encoding = 'gb18030')\n",
    "entity_dict = {}\n",
    "\n",
    "for i in range(len(entity_data)):\n",
    "    line = entity_data.iloc[i, :]\n",
    "    for word in line.entity_name.split('|'):\n",
    "        jieba.add_word(word)\n",
    "        if word in entity_dict:\n",
    "            entity_dict[word].append(line.entity_id)\n",
    "        else:\n",
    "            entity_dict[word] = [line.entity_id]\n",
    "\n",
    "# 对每句句子识别并匹配实体     \n",
    "\n",
    "valid_data = pd.read_csv('../data/entity_disambiguation/valid_data.csv', encoding = 'gb18030')\n",
    "\n",
    "result_data = []\n",
    "for i in range(len(valid_data)):\n",
    "    line = valid_data.iloc[i, :]\n",
    "    ret =[]  # 存储实体的坐标和序号\n",
    "    loc = 0\n",
    "    window = 10  # 观察上下文的窗口大小\n",
    "    sentence = jieba.lcut(line.sentence)\n",
    "    ret = []\n",
    "    for idx, word in enumerate(sentence):\n",
    "        if word in entity_dict:\n",
    "            max_similar = 0\n",
    "            max_entity_id = 0\n",
    "            context = sentence[max(0, idx-window):min(len(sentence)-1, idx+window)]\n",
    "            for ids in entity_dict[word]:\n",
    "                similar = len(set(context)&set(jieba.lcut(entity_data[entity_data.entity_id.isin([ids])].reset_index().desc[0])))\n",
    "                if max_similar>similar:\n",
    "                    max_similar = similar\n",
    "                    max_entity_id = ids\n",
    "            ret.append(str(loc)+'-'+str(loc+len(word))+':'+str(ids))\n",
    "        loc+=len(word)\n",
    "    result_data.append([i, '|'.join(ret)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, '3-6:1008|109-112:1008|187-190:1008'],\n",
       " [1, '18-21:1008'],\n",
       " [2, '23-26:1008|40-43:1008'],\n",
       " [3, '7-10:1008'],\n",
       " [4, '2-5:1008|14-17:1008'],\n",
       " [5, '28-30:1003|34-36:1003|41-43:1003'],\n",
       " [6, '4-8:1001|25-27:1003|34-36:1003|100-102:1003'],\n",
       " [7, '0-2:1003|6-10:1001|19-21:1003|34-36:1003|45-47:1003'],\n",
       " [8, '8-10:1003|22-24:1003|34-36:1003|37-39:1003|46-48:1003'],\n",
       " [9, '14-16:1003'],\n",
       " [10, '0-2:1005|39-44:1005'],\n",
       " [11, '7-11:1005|20-22:1005'],\n",
       " [12, '4-6:1005|29-31:1005|62-64:1005'],\n",
       " [13, '26-28:1005'],\n",
       " [14, '0-2:1005|24-26:1005'],\n",
       " [15, '10-12:1005|28-30:1005'],\n",
       " [16, '6-8:1005|20-22:1005'],\n",
       " [17, '8-12:1011|26-30:1011'],\n",
       " [18, '9-13:1011|28-30:1013'],\n",
       " [19, '0-2:1013|18-20:1013'],\n",
       " [20, '6-8:1013'],\n",
       " [21, '0-2:1013|26-28:1013|41-43:1013'],\n",
       " [22, '0-2:1013|20-22:1013'],\n",
       " [23, '0-2:1013'],\n",
       " [24, '0-2:1013|32-34:1013'],\n",
       " [25, '0-3:1016'],\n",
       " [26, '2-5:1016|11-14:1016|18-21:1016'],\n",
       " [27, '20-23:1016'],\n",
       " [28, '11-14:1016']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result_data).to_csv('../submit/entity_disambiguation_submit.csv', index=False)\n",
    "result_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 实体识别\n",
    "\n",
    "借助开源工具，对实体进行识别。\n",
    "\n",
    "将每句句子中实体识别出，存入实体词典，并用特殊符号替换语句。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(28, 33, 'company', '国泰君安'), (0, 13, 'company', '深圳能源集团股份有限公司')]]\n",
      "[[(36, 49, 'company', '远大产业控股股份有限公司'), (0, 13, 'company', '远大产业控股股份有限公司')]]\n",
      "[[(104, 109, 'company', '河北银行'), (88, 99, 'company', '河北银行股份有限公司'), (61, 74, 'company', '南京栖霞建设集团有限公司'), (34, 47, 'company', '南京栖霞建设股份有限公司')]]\n",
      "[[(189, 196, 'time', '2015年度'), (185, 190, 'company', '歌礼制药'), (160, 165, 'company', '康桥资本'), (136, 150, 'company', '天士力（香港）药业有限公司'), (88, 114, 'company', 'CBCInvestmentSevenLimited'), (81, 86, 'company', '康桥资本'), (44, 58, 'company', '天士力（香港）药业有限公司'), (19, 33, 'company', '天士力医药集团股份有限公司'), (2, 16, 'company', '天士力制药集团股份有限公司')]]\n",
      "[[(44, 59, 'company', '江苏康缘美域生物医药有限公司'), (21, 37, 'company', '连云港康缘美域保健食品有限公司'), (6, 19, 'company', '江苏康缘药业股份有限公司'), (0, 6, 'time', '2016年')]]\n",
      "[[(74, 85, 'company', '康缘国际实业有限公司'), (60, 73, 'company', '江苏康缘药业股份有限公司'), (39, 52, 'company', '江苏康缘集团有限责任公司'), (21, 32, 'company', '康缘国际实业有限公司'), (6, 19, 'company', '江苏康缘药业股份有限公司'), (0, 6, 'time', '2015年')]]\n",
      "[[(27, 33, 'company', '天津大西洋'), (10, 24, 'company', '天津大西洋焊接材料有限公司'), (3, 9, 'location', '上海大西洋'), (0, 4, 'time', '本年度')]]\n"
     ]
    }
   ],
   "source": [
    "# code\n",
    "# 首先尝试利用开源工具分出实体\n",
    "\n",
    "import fool\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "sample_data = pd.read_csv('../data/info_extract/samples_test.csv', encoding = 'utf-8', header=0)\n",
    "sample_data['ner'] = None\n",
    "ner_id = 1001\n",
    "ner_dict = {}  # 存储所有实体\n",
    "ner_dict_reverse = {}  # 存储所有实体\n",
    "for i in range(len(sample_data)):\n",
    "    sentence = copy(sample_data.iloc[i, 1])\n",
    "    words, ners = fool.analysis(sentence)\n",
    "    ners[0].sort(key=lambda x:x[0], reverse=True)\n",
    "    print(ners)\n",
    "    for start, end, ner_type, ner_name in ners[0]:\n",
    "        if ner_name not in ner_dict:\n",
    "            ner_dict[ner_name] = ner_id\n",
    "            ner_dict_reverse[ner_id] = ner_name\n",
    "            ner_id+=1\n",
    "        sentence = sentence[:start] + ' ner_' + str(ner_dict[ner_name]) + '_ ' + sentence[end-1:]\n",
    "    sample_data.iloc[i, 2] = sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>深圳能源集团股份有限公司拟按现有2.03%的持股比例参与国泰君安本次可转换公司债的配售，参与...</td>\n",
       "      <td>ner_1002_ 拟按现有2.03%的持股比例参与 ner_1001_ 本次可转换公司债...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>远大产业控股股份有限公司于报告期实施的发行股份购买资产的交易对方中金波为远大产业控股股份有限...</td>\n",
       "      <td>ner_1003_ 于报告期实施的发行股份购买资产的交易对方中金波为 ner_1003_ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>一、根据公司第六届董事会第七次会议审议并通过的公司重大资产重组方案，南京栖霞建设股份有限公司...</td>\n",
       "      <td>一、根据公司第六届董事会第七次会议审议并通过的公司重大资产重组方案， ner_1007_ 拟...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>一、天士力制药集团股份有限公司（简称“天士力医药集团股份有限公司”、“公司”）拟向子公司天士...</td>\n",
       "      <td>一、 ner_1014_ （简称“ ner_1013_ ”、“公司”）拟向子公司 ner_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2016年，江苏康缘药业股份有限公司将持有连云港康缘美域保健食品有限公司的股权全部转让给江苏...</td>\n",
       "      <td>ner_1018_ ， ner_1017_ 将持有 ner_1016_ 的股权全部转让给 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2015年，江苏康缘药业股份有限公司将持有康缘国际实业有限公司的股权全部转让给江苏康缘集团有...</td>\n",
       "      <td>ner_1021_ ， ner_1017_ 将持有 ner_1019_ 的股权全部转让给 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>本年度上海大西洋收购天津大西洋焊接材料有限公司将其所持天津大西洋销售44%股权，支付对价8，...</td>\n",
       "      <td>ner_1025_  ner_1024_ 收购 ner_1023_ 将其所持 ner_10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence  \\\n",
       "0   1  深圳能源集团股份有限公司拟按现有2.03%的持股比例参与国泰君安本次可转换公司债的配售，参与...   \n",
       "1   2  远大产业控股股份有限公司于报告期实施的发行股份购买资产的交易对方中金波为远大产业控股股份有限...   \n",
       "2   3  一、根据公司第六届董事会第七次会议审议并通过的公司重大资产重组方案，南京栖霞建设股份有限公司...   \n",
       "3   4  一、天士力制药集团股份有限公司（简称“天士力医药集团股份有限公司”、“公司”）拟向子公司天士...   \n",
       "4   5  2016年，江苏康缘药业股份有限公司将持有连云港康缘美域保健食品有限公司的股权全部转让给江苏...   \n",
       "5   6  2015年，江苏康缘药业股份有限公司将持有康缘国际实业有限公司的股权全部转让给江苏康缘集团有...   \n",
       "6   7  本年度上海大西洋收购天津大西洋焊接材料有限公司将其所持天津大西洋销售44%股权，支付对价8，...   \n",
       "\n",
       "                                                 ner  \n",
       "0   ner_1002_ 拟按现有2.03%的持股比例参与 ner_1001_ 本次可转换公司债...  \n",
       "1   ner_1003_ 于报告期实施的发行股份购买资产的交易对方中金波为 ner_1003_ ...  \n",
       "2  一、根据公司第六届董事会第七次会议审议并通过的公司重大资产重组方案， ner_1007_ 拟...  \n",
       "3  一、 ner_1014_ （简称“ ner_1013_ ”、“公司”）拟向子公司 ner_1...  \n",
       "4   ner_1018_ ， ner_1017_ 将持有 ner_1016_ 的股权全部转让给 ...  \n",
       "5   ner_1021_ ， ner_1017_ 将持有 ner_1019_ 的股权全部转让给 ...  \n",
       "6   ner_1025_  ner_1024_ 收购 ner_1023_ 将其所持 ner_10...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 实体统一\n",
    "对同一实体具有多个名称的情况进行统一，将多种称谓统一到一个实体上，并体现在实体的属性中（可以给实体建立“别称”属性）\n",
    "\n",
    "公司名称有其特点，例如后缀可以省略、上市公司的地名可以省略等等。在data/dict目录中提供了几个词典，可供实体统一使用。\n",
    "- company_suffix.txt是公司的通用后缀词典\n",
    "- company_business_scope.txt是公司经营范围常用词典\n",
    "- co_Province_Dim.txt是省份词典\n",
    "- co_City_Dim.txt是城市词典\n",
    "- stopwords.txt是可供参考的停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "#功能：从输入的“公司名”中提取主体(列表形式)\n",
    "def main_extract(input_str,stop_word,d_4_delete,d_city_province):\n",
    "    input_str = replace(input_str,d_city_province)\n",
    "    #开始分词\n",
    "    seg = pseg.cut(input_str)\n",
    "    seg_lst = []\n",
    "    for w in seg:\n",
    "        elmt = w.word\n",
    "        if elmt not in d_4_delete:\n",
    "            seg_lst.append(elmt)\n",
    "    seg_lst = remove_word(seg_lst,stop_word)\n",
    "    seg_lst = city_prov_ahead(seg_lst,d_city_province)\n",
    "    return seg_lst\n",
    "\n",
    "    \n",
    "\n",
    "#功能：将list中地名提前\n",
    "def city_prov_ahead(seg_lst,d_city_province):\n",
    "    city_prov_lst = []\n",
    "    for seg in seg_lst:\n",
    "        if seg in d_city_province:\n",
    "            city_prov_lst.append(seg)\n",
    "            seg_lst.remove(seg)\n",
    "    city_prov_lst.sort()\n",
    "    return city_prov_lst+seg_lst\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "#功能：去除停用词\n",
    "def remove_word(seg,sw):\n",
    "    ret = []\n",
    "    for i in range(len(seg)):\n",
    "        if seg[i] not in sw:\n",
    "            ret.append(seg[i])\n",
    "    return ret\n",
    "\n",
    "\n",
    "#功能：替换com，dep的内容\n",
    "def replace(com,d_city_province):\n",
    "    #————————公司、部门\n",
    "    #替换\n",
    "    #'*'\n",
    "    com = re.sub(r'(\\*)*(\\#)*(\\-)*(\\—)*(\\~)*(\\.)*(\\/)*(\\?)*(\\!)*(\\？)*(\\\")*','',com)\n",
    "    #'、'\n",
    "    com = re.sub(r'(\\、)*','',com)\n",
    "    #'+'\n",
    "    com = re.sub(r'(\\+)*','',com)\n",
    "    #','\n",
    "    com = re.sub(r'(\\,)+',' ',com)\n",
    "    #'，'\n",
    "    com = re.sub(r'(\\，)+',' ',com)\n",
    "    #':'\n",
    "    com = re.sub(r'(\\:)*','',com)\n",
    "    #[]【】都删除\n",
    "    com = re.sub(r'\\【.*?\\】','',com)\n",
    "    com = re.sub(r'\\[.*?\\]','',com)\n",
    "    #数字在结尾替换为‘’\n",
    "    com = re.sub(r'\\d*$',\"\",com)\n",
    "    #'&nbsp;'或‘&lt;’替换为‘’\n",
    "    com = re.sub(r'(&gt;)*(&nbsp;)*(&lt;)*',\"\",com)\n",
    "    #地名\n",
    "    com = re.sub(r'\\(',\"（\",com)\n",
    "    com = re.sub(r'\\)',\"）\",com)\n",
    "    pat = re.search(r'\\（.+?\\）',com)\n",
    "    while pat:\n",
    "        v = pat.group()[3:-3]\n",
    "        start = pat.span()[0]\n",
    "        end = pat.span()[1]\n",
    "        if v not in d_city_province:\n",
    "            com = com[:start]+com[end:]\n",
    "        else:\n",
    "            com = com[:start]+com[start+3:end-3]+com[end:]\n",
    "        pat = re.search(r'\\（.+?\\）',com)\n",
    "    #()（）\n",
    "    com = re.sub(r'(\\()*(\\))*(\\（)*(\\）)*','',com)\n",
    "    #全数字\n",
    "    com = re.sub(r'^(\\d)+$',\"\",com)\n",
    "    return com\n",
    "\n",
    "\n",
    "\n",
    "#初始加载步骤\n",
    "#输出“用来删除的字典”和“stop word”\n",
    "def my_initial():\n",
    "    fr1 = open(r\"../data/dict/co_City_Dim.txt\", encoding='utf-8')\n",
    "    fr2 = open(r\"../data/dict/co_Province_Dim.txt\", encoding='utf-8')\n",
    "    fr3 = open(r\"../data/dict/company_business_scope.txt\", encoding='utf-8')\n",
    "    fr4 = open(r\"../data/dict/company_suffix.txt\", encoding='utf-8')\n",
    "    #城市名\n",
    "    lines1 = fr1.readlines()\n",
    "    d_4_delete = []\n",
    "    d_city_province = [re.sub(r'(\\r|\\n)*','',line) for line in lines1]\n",
    "    #省份名\n",
    "    lines2 = fr2.readlines()\n",
    "    l2_tmp = [re.sub(r'(\\r|\\n)*','',line) for line in lines2]\n",
    "    d_city_province.extend(l2_tmp)\n",
    "    #公司后缀\n",
    "    lines3 = fr3.readlines()\n",
    "    l3_tmp = [re.sub(r'(\\r|\\n)*','',line) for line in lines3]\n",
    "    lines4 = fr4.readlines()\n",
    "    l4_tmp = [re.sub(r'(\\r|\\n)*','',line) for line in lines4]\n",
    "    d_4_delete.extend(l4_tmp)\n",
    "    #get stop_word\n",
    "    fr = open(r'../data/dict/stopwords.txt', encoding='utf-8')   \n",
    "    stop_word = fr.readlines()\n",
    "    stop_word_after = [re.sub(r'(\\r|\\n)*','',stop_word[i]) for i in range(len(stop_word))]\n",
    "    stop_word_after[-1] = stop_word[-1]\n",
    "    stop_word = stop_word_after\n",
    "    return d_4_delete,stop_word,d_city_province\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "河北银行\n"
     ]
    }
   ],
   "source": [
    "d_4_delete,stop_word,d_city_province = my_initial()\n",
    "company_name = \"河北银行股份有限公司\"\n",
    "lst = main_extract(company_name,stop_word,d_4_delete,d_city_province)\n",
    "company_name = ''.join(lst)  # 对公司名提取主体部分，将包含相同主体部分的公司统一为一个实体\n",
    "print(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在语句中统一实体\n",
    "\n",
    "import fool\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "sample_data = pd.read_csv('../data/info_extract/samples_test.csv', encoding = 'utf-8', header=0)\n",
    "sample_data['ner'] = None\n",
    "ner_id = 1001\n",
    "ner_dict_new = {}  # 存储所有实体\n",
    "ner_dict_reverse_new = {}  # 存储所有实体\n",
    "for i in range(len(sample_data)):\n",
    "    sentence = copy(sample_data.iloc[i, 1])\n",
    "    words, ners = fool.analysis(sentence)\n",
    "    ners[0].sort(key=lambda x:x[0], reverse=True)\n",
    "    print(ners)\n",
    "    for start, end, ner_type, ner_name in ners[0]:\n",
    "        company_main_name = ''.join(main_extract(ner_name,stop_word,d_4_delete,d_city_province))  # 提取公司主体名称\n",
    "        if company_main_name not in ner_dict:\n",
    "            ner_dict[company_main_name] = ner_id\n",
    "            ner_id+=1\n",
    "        sentence = sentence[:start] + ' ner_' + str(ner_dict[company_main_name]) + '_ ' + sentence[end-1:]\n",
    "    sample_data.iloc[i, 2] = sentence\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 关系抽取\n",
    "借助句法分析工具，和实体识别的结果，以及正则表达式，设定模版抽取关系，并存储进图数据库。\n",
    "\n",
    "本次要求抽取股权交易关系，关系为有向边，由投资方指向被投资方。\n",
    "\n",
    "模板建立可以使用“正则表达式”、“实体间距离”、“实体上下文”、“依存句法”等。\n",
    "\n",
    "答案提交在submit目录中，命名为info_extract_submit.csv和info_extract_entity.csv。\n",
    "- info_extract_entity.csv格式为：第一列是实体编号，第二列是实体名（多个实体名用“|”分隔）\n",
    "- info_extract_submit.csv格式为：第一列是关系发起方实体编号，第二列为关系接收方实体编号。\n",
    "\n",
    "*成绩以抽取的关系准确率以及召回率综合的F值评分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 建立种子模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "\n",
    "# 最后提交文件为识别出的整个投资图谱，以及图谱中结点列表与属性。\n",
    "\n",
    "# 建立模板\n",
    "import re\n",
    "\n",
    "rep1 = re.compile(r'(ner_\\d\\d\\d\\d)_\\s+收购\\s+(ner_\\d\\d\\d\\d)_')  # 例子模板\n",
    "\n",
    "relation_list = []  # 存储已经提取的关系\n",
    "for i in range(len(sample_data)):\n",
    "    sentence = copy(sample_data.iloc[i, 2])\n",
    "    for v in rep1.findall(sentence+sentence):\n",
    "        relation_list.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ner_1024', 'ner_1023'), ('ner_1024', 'ner_1023')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用bootstrapping搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 存储进图数据库\n",
    "\n",
    "本次作业我们使用neo4j作为图数据库，neo4j需要java环境，请先配置好环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from py2neo import Node, Relationship, Graph\n",
    "\n",
    "graph = Graph(\n",
    "    \"http://localhost:7474\", \n",
    "    username=\"neo4j\", \n",
    "    password=\"person\"\n",
    ")\n",
    "\n",
    "for v in relation_list:\n",
    "    a = Node('Company', name=v[0])\n",
    "    b = Node('Company', name=v[1])\n",
    "    r = Relationship(a, 'INVEST', b)\n",
    "    s = a | b | r\n",
    "    graph.create(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ner_1024)-[:INVEST {}]->(ner_1023)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
